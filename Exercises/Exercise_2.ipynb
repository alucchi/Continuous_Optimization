{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Functions for Linear Regression\n",
        "Given $(\\mathbf{x}_i,y_i) \\in \\mathbb{R}^p \\times \\mathbb{R}$ for $i = 1, \\ldots, n$, the linear regression algorithm optimizes the mean squared error cost function. This cost function is convex for a linear function $\\hat{y}_i = {\\mathbf{w}^\\top}\\mathbf{x}_i + \\mathbf{w}_0$. This imlies that if gradient descent converges, it will approach the global minimum of the cost function.\n",
        "\n",
        "Specifically, the loss function used for training the linear regression algorithm is the mean-squared error (MSE). It is given mathematically as:\n",
        "\n",
        "$$J(\\mathbf{w}) = \\frac{1}{2n}\\|\\mathbf{y}-\\hat{\\mathbf{y}}\\|^2 = \\frac{1}{2n}\\sum_i^n (y_i - \\hat{y_i})^2$$\n",
        "\n",
        "<hr> </hr>\n",
        "\n",
        "### Gradient:\n",
        "\n",
        "The gradient of $J(\\mathbf{w})$ wrt $\\mathbf{w}$ is calculated as:\n",
        "\n",
        "$$\\nabla_{\\mathbf{\\mathbf{w}}} J = {1 \\over n}\\sum^n_{i=1}\\bigg[(\\hat{y_i} â€“ y_i)\\mathbf{x}_i \\bigg],$$and the gradient descent update rule is given as follows:\n",
        "$$ \\mathbf{w}^{t+1} = \\mathbf{w}^{t+1} - \\rho \\nabla_\\mathbf{w} J,$$\n",
        "where $\\rho > 0$ is the step size (or learning rate)."
      ],
      "metadata": {
        "id": "-BEoNaRQKves"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "KPNOzys4LKH9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgWZeGrSKSby"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent Class"
      ],
      "metadata": {
        "id": "8R4GVrqeLQGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    This is Gradient Descent module\n",
        "    To use:\n",
        "        # Import the regularizedLR class from the module and use its methods\n",
        "        model = GD()      # Initialization with default params\n",
        "        model.fit(X, y)    # Fit with train set\n",
        "        model.predict(X)   # Make predictions with test set\n",
        "        model.score(X,y)   # Get accuracy score\n",
        "\n",
        "    Method:\n",
        "        __init__\n",
        "        predict\n",
        "        score\n",
        "        fit\n",
        "\"\"\"\n",
        "\n",
        "# Define placeholders for strong iterates, loss function and its gradient values\n",
        "iterates = []\n",
        "losses = []\n",
        "gradients = []\n",
        "\n",
        "class GD:\n",
        "    def __init__(self, lr=0.0001, max_iter=100):\n",
        "        self.lr = lr\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    # Hypothesis function\n",
        "    def predict(self, w, X):\n",
        "        return X @ w\n",
        "\n",
        "    # scoring function, returns the coefficient of determination between predicted and true values\n",
        "    def score(self, y, y_pred):\n",
        "        return r2_score(y, y_pred)\n",
        "\n",
        "    # Loss function, implements mean squared error (MSE)\n",
        "    def J(self, y_pred, y):\n",
        "        n = y.shape[0]\n",
        "        error_vec = y_pred - y.squeeze(-1)\n",
        "        # get the loss\n",
        "        loss = (0.5 / n ) * np.linalg.norm(error_vec)\n",
        "\n",
        "        return loss, error_vec\n",
        "\n",
        "    # reshaping the data matrix X, i.e., adding an additional dimension, to account for the bias term in the weight vector\n",
        "    @staticmethod\n",
        "    def reshape(X):\n",
        "      X = np.block([np.ones((X.shape[0], 1)), X])\n",
        "      return X\n",
        "\n",
        "    # Gradient descent algorithm\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        X = GD.reshape(X)\n",
        "\n",
        "        # Number of features (X)\n",
        "        self.n = X.shape[0]\n",
        "\n",
        "        # initialize the vector, feel free to play with initialization\n",
        "        # ------------------------------------------------------------\n",
        "        np.random.seed(47)\n",
        "        self.w = np.random.normal(size=(X.shape[1], ))\n",
        "        # ------------------------------------------------------------\n",
        "\n",
        "        for epoch in range(self.max_iter):\n",
        "\n",
        "            # Predicted value of output\n",
        "            #  TODO: Get predictions for the current w\n",
        "            # y_pred = ...\n",
        "\n",
        "            # Calculate loss\n",
        "            # TODO: obtain the loss and error\n",
        "            # loss, e = ...\n",
        "            losses.append(loss)\n",
        "            iterates.append(self.w)\n",
        "\n",
        "            # Gradient of loss function with respect to w\n",
        "            #  TODO: Write the gradient expression below\n",
        "            # grad_w =  ...\n",
        "            gradients.append(grad_w)\n",
        "\n",
        "            # Update w with Gradient Descent\n",
        "            # TODO: write the gradient descent update rule with the information collected so far\n",
        "            # self.w =  ...\n"
      ],
      "metadata": {
        "id": "arNePSyMLOIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting functions"
      ],
      "metadata": {
        "id": "Gwh8nQ1JLXEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(X, y, iterates, loss, i = 0, j=3):\n",
        "\n",
        "  \"\"\"\n",
        "      This is visualization fucntion for our results\n",
        "      Displays:\n",
        "      1. Loss [J(w)] Converegnce vs epochs\n",
        "      2. J(w) - J(w^*) converegnce vs epochs, where w_star is the closed form optimal solution\n",
        "      3. J(w) vs ||w||\n",
        "      4. ||w - w^*|| vs ephochs\n",
        "      5. J(w) vs w_i\n",
        "      6. J(w) vs w_j\n",
        "  \"\"\"\n",
        "\n",
        "  fig, ax = plt.subplots(2, 3,figsize = (20, 10))\n",
        "\n",
        "  #  For Loss Converegnce wrt to epochs\n",
        "  # --------------------------------------------------------------------------------------------\n",
        "  ax[0][0].plot(np.array(loss), '--bo', mfc='r', mec='none', markersize=5)\n",
        "  ax[0][0].set_title('Loss vs #epochs')\n",
        "  ax[0][0].set_xlabel(\"epochs\")\n",
        "  ax[0][0].set_ylabel(r\"$\\log \\: J(\\mathbf{w})$\")\n",
        "  ax[0][0].set_yscale('log')\n",
        "  ax[0][0].grid()\n",
        "\n",
        "\n",
        "  #  For Loss(w) - Loss(w_star) converegnce wrt epochs\n",
        "  X = GD().reshape(X)\n",
        "  w_star = np.linalg.inv(X.T@X)@X.T@y\n",
        "  loss_star, _ = GD().J(X@w_star, y)\n",
        "  # --------------------------------------------------------------------------------------------\n",
        "  ax[0][1].plot(np.array(loss)-loss_star, '--bo', mfc='r', mec='none', markersize=5)\n",
        "  ax[0][1].set_title(r'$Loss(\\mathbf{w}) - Loss(\\mathbf{w}^*)$ vs #epochs')\n",
        "  ax[0][1].set_xlabel(\"epochs\")\n",
        "  ax[0][1].set_ylabel(r\"$J(\\mathbf{w}) - J(\\mathbf{w}^*)$\")\n",
        "  # ax[0][1].set_yscale('log') (log-scale)\n",
        "  ax[0][1].grid()\n",
        "\n",
        "\n",
        "  # J(w) vs ||w||\n",
        "  # --------------------------------------------------------------------------------------------\n",
        "  ax[0][2].plot(np.linalg.norm(iterates, axis = 1), np.array(loss), '--bo', mfc='r', mec='none', markersize=5)\n",
        "  ax[0][2].set_title(r'Loss vs $||\\mathbf{w}||$')\n",
        "  ax[0][2].set_xlabel(r\"$||\\mathbf{w}||$\")\n",
        "  # ax[0][2].set_ylabel(r\"$J$ (log-scale)\")\n",
        "  ax[0][2].grid()\n",
        "\n",
        "\n",
        "  # || w - w^*|| vs ephochs\n",
        "  # --------------------------------------------------------------------------------------------\n",
        "  ax[1][0].plot(np.linalg.norm(np.array(iterates)-w_star.squeeze(-1), axis = 1), '--bo', mfc='r', mec='none', markersize=5)\n",
        "  ax[1][0].set_title(r'Pointwise Convergence')\n",
        "  ax[1][0].set_xlabel(r\"epochs\")\n",
        "  ax[1][0].set_ylabel(r\"$||\\mathbf{w} - \\mathbf{w}^*||$\")\n",
        "  ax[1][0].grid()\n",
        "\n",
        "\n",
        "   #  For loss convergence wrt individual theta components\n",
        "  # ------------\n",
        "  # wrt theta_i\n",
        "  # ------------\n",
        "  ax[1][1].plot(np.array(iterates)[:,i], loss, '--bo', mfc='red', mec='none', markersize=5)\n",
        "  ax[1][1].set_title(r'Loss vs $\\mathbf{w}$'+f'{i}')\n",
        "  ax[1][1].set_xlabel(r'$\\mathbf{w}$'+f'{i}')\n",
        "  ax[1][1].set_ylabel(r'$J(\\mathbf{w}$'+f'{i})')\n",
        "  ax[1][1].grid()\n",
        "\n",
        "   #  For loss convergence wrt individual theta components\n",
        "  # ------------\n",
        "  # wrt theta_j\n",
        "  # ------------\n",
        "  ax[1][2].plot(np.array(iterates)[:,j], loss, '--bo', mfc='red', mec='none', markersize=5)\n",
        "  ax[1][2].set_title(r'Loss vs $\\mathbf{w}$'+f'{j}')\n",
        "  ax[1][2].set_xlabel(r'$\\mathbf{w}$'+f'{j}')\n",
        "  ax[1][2].set_ylabel(r'$J(\\mathbf{w}$'+f'{j})')\n",
        "  ax[1][2].grid()\n",
        "\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Fh5kBb_Ks23d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multivariable Case\n",
        "## Loading data"
      ],
      "metadata": {
        "id": "YQilG6TgLePt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe from csv file, replace it with your local path!\n",
        "PATH = '/content/MultipleLR.csv'\n",
        "df = pd.read_csv(PATH, header=None)\n",
        "# df = pd.read_csv('MultipleLR.csv', header=None)\n",
        "data = df.to_numpy()\n",
        "\n",
        "print(\"Shape of data: \", data.shape)\n",
        "data[:5,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "KGwGjeOtLbum",
        "outputId": "36aa4d53-dc54-4881-c032-f57cfd692410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6285621b7411>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dataframe from csv file, replace it with your local path!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/MultipleLR.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# df = pd.read_csv('MultipleLR.csv', header=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/MultipleLR.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train/test split"
      ],
      "metadata": {
        "id": "jyZn1MccMSvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data[:, [-1]]\n",
        "X = data[:, 0:3]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "__qBHku1MP9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model initialization"
      ],
      "metadata": {
        "id": "FxxuVgquMauw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = GD(lr=1e-5, max_iter=50)"
      ],
      "metadata": {
        "id": "WOUlo9AwMW67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "pdOnI9q5MfbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "og0Hnsr5Mdux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training graphs"
      ],
      "metadata": {
        "id": "fjZWrmtOOHhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualize(X, y, iterates, losses)"
      ],
      "metadata": {
        "id": "DA4khMsEOFou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training evaluation"
      ],
      "metadata": {
        "id": "Ve84dQfAOM28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = model.predict(iterates[-1], GD.reshape(X_train))\n",
        "print(f'The r2_score for training is {r2_score(y_train, y_pred_train)}')"
      ],
      "metadata": {
        "id": "zUmF1MVLOKYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ],
      "metadata": {
        "id": "HfASK9W_ORg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = model.predict(iterates[-1], GD.reshape(X_test))"
      ],
      "metadata": {
        "id": "AQr5ubjdOPpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test evaluation"
      ],
      "metadata": {
        "id": "hKvb9sKgOWrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(r'The coefficient of determination ($R^2$) for test is :', model.score(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "6E5GwUJrOVG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2a0E4jYAINZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}